{"cells":[{"cell_type":"markdown","metadata":{"id":"JmPYsg-B49tM"},"source":["# Prepare Google Colab Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":725,"status":"ok","timestamp":1655104912718,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"},"user_tz":-120},"id":"GbkVr03HbnG4","outputId":"4688abe6-515e-43c4-a105-90a6010ee50d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'STEGO'...\n","remote: Enumerating objects: 201, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (20/20), done.\u001b[K\n","remote: Total 201 (delta 18), reused 15 (delta 12), pack-reused 169\u001b[K\n","Receiving objects: 100% (201/201), 9.23 MiB | 45.02 MiB/s, done.\n","Resolving deltas: 100% (98/98), done.\n"]}],"source":["!git clone https://github.com/mhamilton723/STEGO.git"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76863,"status":"ok","timestamp":1657378562045,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"},"user_tz":-120},"id":"Q4z1D5fOda3F","outputId":"4ab7a393-abb1-4e91-a220-1b54b94e78c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.7.1)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n","  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-q6ovmarg\n","  Running command git clone -q https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-q6ovmarg\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pydensecrf\n","  Building wheel for pydensecrf (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pydensecrf: filename=pydensecrf-1.0rc2-cp37-cp37m-linux_x86_64.whl size=2782046 sha256=71473ff2b3a4363bda9ceb8f46de25bb51b6d2b7727d03a5ff5f312642aa3e63\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uvn8sinm/wheels/c1/7e/80/99adc0b2f215180486e24dd9c700028343ba5f566514a0ef05\n","Successfully built pydensecrf\n","Installing collected packages: pydensecrf\n","Successfully installed pydensecrf-1.0rc2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (2.2.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n","\u001b[K     |████████████████████████████████| 585 kB 31.1 MB/s \n","\u001b[?25hRequirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.9.2)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Collecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.17.3)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 73.5 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.11.0+cu113)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 60.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.46.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.1.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 26.4 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 67.2 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, pyDeprecate, pytorch-lightning\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 yarl-1.7.2\n"]}],"source":["!pip install wget\n","!pip install torchmetrics\n","!pip install hydra-core\n","!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n","!pip install omegaconf\n","!pip install pytorch-lightning"]},{"cell_type":"markdown","metadata":{"id":"N-CjEZdF5DSH"},"source":["# Download Pretrained Model\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29946,"status":"ok","timestamp":1657378345420,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"},"user_tz":-120},"id":"T4vf1VweyKfA","outputId":"c7e2e5a1-af69-44e4-b743-bf156dc7ec08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"hJ_XE2xHcImN","executionInfo":{"status":"ok","timestamp":1657378881958,"user_tz":-120,"elapsed":1087,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"}}},"outputs":[],"source":["import os\n","from os.path import join\n","import shutil\n","os.chdir(\"/content/drive/MyDrive/STEGO/src\")\n","saved_models_dir = join(\"..\", \"saved_models\")\n","os.makedirs(saved_models_dir, exist_ok=True)\n","#shutil.copy(\"../checkpoints/litter_dataset/directory_exp1_date_Jun28_09-42-44/epoch=2-step=2400.ckpt\", os.path.join(saved_models_dir,\"trained_model.ckpt\"))\n","#shutil.copy(\"../checkpoints/litter_dataset/directory_exp2_date_Jul06_08-10-48/epoch=3-step=2400.ckpt\", os.path.join(saved_models_dir,\"trained_model_exp2.ckpt\"))\n","shutil.copy(\"../checkpoints/litter_dataset/directory_exp3_date_Jul09_14-45-58/epoch=3-step=2400.ckpt\", os.path.join(saved_models_dir,\"trained_model_exp3.ckpt\"))\n","saved_model_name = \"trained_model_exp3.ckpt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knywSO7IcNc2"},"outputs":[],"source":["#import wget\n","#saved_model_url_root = \"https://marhamilresearch4.blob.core.windows.net/stego-public/saved_models/\"\n","#saved_model_name = \"cocostuff27_vit_base_5.ckpt\"\n","#if not os.path.exists(join(saved_models_dir, saved_model_name)):\n","#  wget.download(saved_model_url_root + saved_model_name, join(saved_models_dir, saved_model_name))"]},{"cell_type":"markdown","metadata":{"id":"rtwTZEkA7twI"},"source":["# Load pretrained STEGO"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25701,"status":"ok","timestamp":1657378914209,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"},"user_tz":-120},"id":"RyBXeiGjdN8I","outputId":"aa123fb0-2676-48a4-9a76-34c1aa17566f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading vit tiny pretrained Dino model\n","Pretrained weights found at /content/drive/MyDrive/output_dino/checkpoint0090.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n","                not been set for this class (UnsupervisedMetrics). The property determines if `update` by\n","                default needs access to the full metric state. If this is not the case, significant speedups can be\n","                achieved and we recommend setting this to `False`.\n","                We provide an checking function\n","                `from torchmetrics.utilities import check_forward_no_full_state`\n","                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n","                default for now) or if `full_state_update=False` can be used safely.\n","                \n","  warnings.warn(*args, **kwargs)\n"]}],"source":["from train_segmentation import LitUnsupervisedSegmenter\n","\n","model = LitUnsupervisedSegmenter.load_from_checkpoint(join(saved_models_dir, saved_model_name)).cuda()"]},{"cell_type":"markdown","source":["### Create composite images with predictions from cluster and linear probe"],"metadata":{"id":"ANFdLqN0rWsZ"}},{"cell_type":"code","source":["from utils import unnorm, remove_axes\n","import torch.nn.functional as F\n","from crf import dense_crf\n","import torch\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","from torchvision.transforms.functional import to_tensor\n","from utils import get_transform\n","import glob\n","from skimage.io import imsave\n","import pandas as pd "],"metadata":{"id":"75-W_AV4rVVH","executionInfo":{"status":"ok","timestamp":1657378916695,"user_tz":-120,"elapsed":2494,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["df_lab = pd.read_csv('/content/drive/My Drive/all_labeled.csv', index_col=0)\n","X, Y , imfilename, area = [], [], [], []\n","patch_path = '/content/drive/My Drive/root_patches/patches/'\n","for i in range(len(df_lab)):\n","    f = os.path.basename(df_lab.loc[i,'patch_filename']).replace(\".JPG\", \"\").split('_')\n","    df_lab.loc[i,'patch_filename']=os.path.join(patch_path, os.path.basename(df_lab.loc[i,'patch_filename']))\n","    imfilename.append('_'.join(f[1:3]) + \".JPG\")\n","    area.append(f[0])\n","    X.append(int(f[3].replace(\"X\", \"\")))\n","    Y.append(int(f[4].replace(\"Y\", \"\")))\n","df_lab['X'] = X\n","df_lab['Y'] = Y\n","\n","df_lab['area'] = area\n","df_lab['imfilename'] = imfilename\n","df_lab = df_lab.sort_values(by='imfilename').reset_index(drop=True)\n","df_lab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"QuEg3BovpdjX","executionInfo":{"status":"ok","timestamp":1657378920271,"user_tz":-120,"elapsed":3605,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"}},"outputId":"6c238ee9-b541-48e8-c8b7-b0fb1b5f2cff"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0.1   index                                     patch_filename  \\\n","0             1874  2412.0  /content/drive/My Drive/root_patches/patches/a...   \n","1             1971  2551.0  /content/drive/My Drive/root_patches/patches/a...   \n","2             1948  2527.0  /content/drive/My Drive/root_patches/patches/a...   \n","3              767  2465.0  /content/drive/My Drive/root_patches/patches/a...   \n","4             1831  2363.0  /content/drive/My Drive/root_patches/patches/a...   \n","...            ...     ...                                                ...   \n","7051          2583  4653.0  /content/drive/My Drive/root_patches/patches/a...   \n","7052          2584  4654.0  /content/drive/My Drive/root_patches/patches/a...   \n","7053          2585  4655.0  /content/drive/My Drive/root_patches/patches/a...   \n","7054          2569  4639.0  /content/drive/My Drive/root_patches/patches/a...   \n","7055          2385  4455.0  /content/drive/My Drive/root_patches/patches/a...   \n","\n","      plastic     X     Y area    imfilename  \n","0         0.0  4608   512   a1  DJI_0813.JPG  \n","1         0.0  2560  2304   a1  DJI_0813.JPG  \n","2         0.0  1792  2048   a1  DJI_0813.JPG  \n","3         1.0  2048  1280   a1  DJI_0813.JPG  \n","4         0.0  2816     0   a1  DJI_0813.JPG  \n","...       ...   ...   ...  ...           ...  \n","7051      1.0  3072  2816   a2  DJI_0965.JPG  \n","7052      1.0  3328  2816   a2  DJI_0965.JPG  \n","7053      1.0  3584  2816   a2  DJI_0965.JPG  \n","7054      0.0  4864  2560   a2  DJI_0965.JPG  \n","7055      1.0   768   512   a2  DJI_0965.JPG  \n","\n","[7056 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-d616ebd9-057d-480e-808a-83aacdbd16e5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0.1</th>\n","      <th>index</th>\n","      <th>patch_filename</th>\n","      <th>plastic</th>\n","      <th>X</th>\n","      <th>Y</th>\n","      <th>area</th>\n","      <th>imfilename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1874</td>\n","      <td>2412.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>0.0</td>\n","      <td>4608</td>\n","      <td>512</td>\n","      <td>a1</td>\n","      <td>DJI_0813.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1971</td>\n","      <td>2551.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>0.0</td>\n","      <td>2560</td>\n","      <td>2304</td>\n","      <td>a1</td>\n","      <td>DJI_0813.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1948</td>\n","      <td>2527.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>0.0</td>\n","      <td>1792</td>\n","      <td>2048</td>\n","      <td>a1</td>\n","      <td>DJI_0813.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>767</td>\n","      <td>2465.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>1.0</td>\n","      <td>2048</td>\n","      <td>1280</td>\n","      <td>a1</td>\n","      <td>DJI_0813.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1831</td>\n","      <td>2363.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>0.0</td>\n","      <td>2816</td>\n","      <td>0</td>\n","      <td>a1</td>\n","      <td>DJI_0813.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7051</th>\n","      <td>2583</td>\n","      <td>4653.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>1.0</td>\n","      <td>3072</td>\n","      <td>2816</td>\n","      <td>a2</td>\n","      <td>DJI_0965.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>7052</th>\n","      <td>2584</td>\n","      <td>4654.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>1.0</td>\n","      <td>3328</td>\n","      <td>2816</td>\n","      <td>a2</td>\n","      <td>DJI_0965.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>7053</th>\n","      <td>2585</td>\n","      <td>4655.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>1.0</td>\n","      <td>3584</td>\n","      <td>2816</td>\n","      <td>a2</td>\n","      <td>DJI_0965.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>7054</th>\n","      <td>2569</td>\n","      <td>4639.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>0.0</td>\n","      <td>4864</td>\n","      <td>2560</td>\n","      <td>a2</td>\n","      <td>DJI_0965.JPG</td>\n","    </tr>\n","    <tr>\n","      <th>7055</th>\n","      <td>2385</td>\n","      <td>4455.0</td>\n","      <td>/content/drive/My Drive/root_patches/patches/a...</td>\n","      <td>1.0</td>\n","      <td>768</td>\n","      <td>512</td>\n","      <td>a2</td>\n","      <td>DJI_0965.JPG</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7056 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d616ebd9-057d-480e-808a-83aacdbd16e5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d616ebd9-057d-480e-808a-83aacdbd16e5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d616ebd9-057d-480e-808a-83aacdbd16e5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["exp = 'exp3_res128'\n","if not os.path.exists(os.path.join('/content/drive/My Drive/output_stego_trained/',exp)):\n","  os.makedirs(os.path.join('/content/drive/My Drive/output_stego_trained/', exp, 'cluster_composites'))\n","  os.makedirs(os.path.join('/content/drive/My Drive/output_stego_trained/', exp, 'probe_composites'))"],"metadata":{"id":"H3aprInidiLz","executionInfo":{"status":"ok","timestamp":1657378999257,"user_tz":-120,"elapsed":483,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from skimage.io import imread \n","\n","imgs_path = '/content/drive/My Drive/selected_50m/'\n","imgs = np.unique(df_lab['imfilename'])\n","for imf in imgs:\n","    for a in np.unique(df_lab['area']):\n","        df = df_lab[(df_lab['imfilename']==imf) & (df_lab['area']==a)].reset_index(drop=True)\n","        if len(df)!=0:\n","            im = imread(os.path.join(imgs_path, a, imf))\n","            comp_clus = np.zeros(im.shape)\n","            comp_lin_prob = np.zeros(im.shape)\n","            for i in range(len(df)):\n","                img = Image.open(df.loc[i, 'patch_filename'])\n","                x, y = df.loc[i,'X'], df.loc[i,'Y']\n","                transform = get_transform(256, False, \"center\")\n","                img = transform(img).unsqueeze(0).cuda()\n","\n","                with torch.no_grad():\n","                  code1 = model(img)\n","                  code2 = model(img.flip(dims=[3]))\n","                  code  = (code1 + code2.flip(dims=[3])) / 2\n","                  code = F.interpolate(code, img.shape[-2:], mode='bilinear', align_corners=False)\n","                  linear_probs = torch.log_softmax(model.linear_probe(code), dim=1).cpu()\n","                  cluster_probs = model.cluster_probe(code, 2, log_probs=True).cpu()\n","\n","                  single_img = img[0].cpu()\n","                  linear_pred = dense_crf(single_img, linear_probs[0]).argmax(0)\n","                  cluster_pred = dense_crf(single_img, cluster_probs[0]).argmax(0)\n","                  cluster_img = model.label_cmap[cluster_pred]\n","                  linear_prob_img = model.label_cmap[linear_pred]\n","\n","                  comp_lin_prob[y: y+256 , x: x+256] = linear_prob_img\n","                  comp_clus[y: y+256 , x: x+256] = cluster_img\n","            imsave(os.path.join('/content/drive/My Drive/output_stego_trained/', exp, 'cluster_composites/cluster_pred_'+ imf), comp_clus)\n","            imsave(os.path.join('/content/drive/My Drive/output_stego_trained/', exp, 'probe_composites/linear_prob_'+ imf), comp_lin_prob)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"rheThk7dp_8K","executionInfo":{"status":"error","timestamp":1657381656485,"user_tz":-120,"elapsed":2473835,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"}},"outputId":"7c61015c-f3e5-4c91-f54f-6ecbc306fefe"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 128.0]. Convert image to uint8 prior to saving to suppress this warning.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-316539b830d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcomp_lin_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'patch_filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"center\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"BxPO9i4rBjpH"},"source":["# Visualize Result\n","\n","Note that cluster predictions will not be matched with ground truth classes in this example. For hungarian matching please use: `eval_segmentation.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18_cddOVxnbecAbLyzg4cdFk1L_eHbmlW"},"executionInfo":{"elapsed":195886,"status":"ok","timestamp":1657136591961,"user":{"displayName":"Giorgia Milli","userId":"12096946512569911148"},"user_tz":-120},"id":"3G7CIyYG-hXj","outputId":"99f73dd4-4426-421b-9701-27bf6dc9a690"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","from utils import unnorm, remove_axes\n","import torch.nn.functional as F\n","from crf import dense_crf\n","import torch\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","from torchvision.transforms.functional import to_tensor\n","from utils import get_transform\n","import glob\n","\n","imgs_paths = glob.glob('/content/drive/My Drive/predicted_patches/litter/*.JPG')\n","for imfile in imgs_paths:\n","  if not os.path.exists('/content/drive/My Drive/output_stego_trained/stego_'+ os.path.basename(imfile)):\n","    img = Image.open(imfile)\n","    transform = get_transform(256, False, \"center\")\n","    img = transform(img).unsqueeze(0).cuda()\n","\n","    with torch.no_grad():\n","      code1 = model(img)\n","      code2 = model(img.flip(dims=[3]))\n","      code  = (code1 + code2.flip(dims=[3])) / 2\n","      code = F.interpolate(code, img.shape[-2:], mode='bilinear', align_corners=False)\n","      linear_probs = torch.log_softmax(model.linear_probe(code), dim=1).cpu()\n","      cluster_probs = model.cluster_probe(code, 2, log_probs=True).cpu()\n","\n","      single_img = img[0].cpu()\n","      linear_pred = dense_crf(single_img, linear_probs[0]).argmax(0)\n","      cluster_pred = dense_crf(single_img, cluster_probs[0]).argmax(0)\n","\n","    fig, ax = plt.subplots(1,3, figsize=(5*3,5))\n","    ax[0].imshow(unnorm(img)[0].permute(1,2,0).cpu())\n","    ax[0].set_title(\"Image\")\n","    ax[1].imshow(model.label_cmap[cluster_pred])\n","    ax[1].set_title(\"Cluster Predictions\")\n","    ax[2].imshow(model.label_cmap[linear_pred])\n","    ax[2].set_title(\"Linear Probe Predictions\")\n","    remove_axes(ax)\n","    if not os.path.exists('/content/drive/My Drive/output_stego_trained/'):\n","      os.mkdir('/content/drive/My Drive/output_stego_trained/')\n","    plt.savefig('/content/drive/My Drive/output_stego_trained/stego_'+ os.path.basename(imfile))"]},{"cell_type":"code","source":[""],"metadata":{"id":"3V0cC9a55ldl"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"STEGO_predict.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}